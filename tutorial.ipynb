{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28d18c4a",
   "metadata": {},
   "source": [
    "# Symbolic DAG Search - Tutorial\n",
    "\n",
    "This tutorial is meant to get you familiar with the usage of this module.\n",
    "\n",
    "Basically, we are looking for computational DAG that has the lowest loss for a given input.\n",
    "\n",
    "Let $X\\in \\mathbb{R}^{N\\times m}$ be an input matrix of $N$ samples with dimension $m$.\\\n",
    "Let further $U = \\{f : \\mathbb{R}^m\\rightarrow \\mathbb{R}^n\\}$ be the set of all functions that map $m$-dimensional input to $n$-dimensional output.\n",
    "Then we are looking for \n",
    "\n",
    "\\begin{align*}\n",
    "\\text{argmin}_{f\\in U}L(f_X)\\,,\n",
    "\\end{align*}\n",
    "\n",
    "that is the function that minimizes a loss function $L$ on the function $f$ at the samples $X$.\n",
    "\n",
    "As we shall see later, this is not restricted to regression tasks and can involve any loss that depends on function values or gradients of the function at the input samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe6b19b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from DAG_search import dag_search\n",
    "from DAG_search import comp_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3c8e5e",
   "metadata": {},
   "source": [
    "## Simple Regression\n",
    "\n",
    "The most basic use case is Regression, where we want the function values to fit to some given values. That is we are looking for \n",
    "\n",
    "\\begin{align}\n",
    "\\text{argmin}_{f}\\cfrac{1}{N}\\sum_{i=1}^N\\left(f(X_i) - y_i\\right)^2\n",
    "\\end{align}\n",
    "\n",
    "For simple 1D Problems, we can use the scikit-learn Interface.\n",
    "\n",
    "Note: Following the convention of sklearn regressors, $y$ has to be a 1D vector here.\n",
    "\n",
    "**Example**:\n",
    "\n",
    "Symbolic Regression for the function\n",
    "\n",
    "\\begin{align}\n",
    "f(x) = \\sin(x_0^2) + x_1\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c277b515",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating evaluation orders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 7200/7200 [00:00<00:00, 218552.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total orders: 405\n",
      "Evaluating orders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████▊                                                     | 88/405 [00:12<00:45,  7.00it/s, best_loss=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing best constants\n",
      "Found graph with loss 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DAGRegressor(max_orders=10000, n_calc_nodes=2, positives=array([ True,  True]))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DAGRegressor</label><div class=\"sk-toggleable__content\"><pre>DAGRegressor(max_orders=10000, n_calc_nodes=2, positives=array([ True,  True]))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DAGRegressor(max_orders=10000, n_calc_nodes=2, positives=array([ True,  True]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define regression problem\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(100, 2)\n",
    "y = np.sin(X[:, 0]**2) + X[:, 1]\n",
    "\n",
    "# use regressor\n",
    "est = dag_search.DAGRegressor(n_calc_nodes = 2, max_orders = int(1e4))\n",
    "est.fit(X, y, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b85c91bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle x_{1} + \\sin{\\left(x_{0}^{2} \\right)}$"
      ],
      "text/plain": [
       "x_1 + sin(x_0**2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get symbolic expression\n",
    "est.model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d98fff",
   "metadata": {},
   "source": [
    "or numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15d096f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict\n",
    "pred = est.predict(X)\n",
    "\n",
    "\n",
    "# plotting\n",
    "plt.scatter(X[:, 0], y, label = 'truth')\n",
    "plt.scatter(X[:, 0], pred, marker = 'x', color = 'red', label = 'predicted')\n",
    "plt.legend()\n",
    "plt.ylabel(f'$f(x)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c48460",
   "metadata": {},
   "source": [
    "## Multidimensional Regression\n",
    "\n",
    "In the case of $y\\in\\mathbb{R}^n$ being multidimensional one can either\n",
    "\n",
    "1. treat it as $n$ seperate regression problems. This has the advantage of the search space staying small.\n",
    "2. use a multidimensional loss function. This formulation can make use of shared subexpressions between the outputs.\n",
    "\\begin{align}\n",
    "\\text{argmin}_{f}\\cfrac{1}{Nn}\\sum_{j=1}^n\\sum_{i=1}^N\\left(f(X_i)_j - y_{ij}\\right)^2\n",
    "\\end{align}\n",
    "\n",
    "In case of 1. refer to the example above or use the following example with $n=1$. In case of 2. we support two different methods:\n",
    "\n",
    "1. **Exhaustive search**: Builds up function skeletons and then tests each assignment of operators to each skeleton.\n",
    "2. **Sample search**: Randomly samples functions and evaluates them.\n",
    "\n",
    "Both methods return their solutions in the form of computational DAGs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0418e06",
   "metadata": {},
   "source": [
    "**Example**: \n",
    "\n",
    "Symbolic Regression for the function\n",
    "\n",
    "\\begin{align}\n",
    "f(x) = \\begin{bmatrix}\n",
    "0.5x\\\\\n",
    "-x\n",
    "\\end{bmatrix}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f497c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem definition\n",
    "X = np.random.rand(100, 1)\n",
    "c = 0.5\n",
    "y = np.column_stack([c*X[:,0], -X[:,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1067473",
   "metadata": {},
   "source": [
    "### Exhaustive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "689eea4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating evaluation orders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 864/864 [00:00<00:00, 92485.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total orders: 305\n",
      "Evaluating orders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/305 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# search\u001b[39;00m\n\u001b[0;32m      5\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m : X,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_outps\u001b[39m\u001b[38;5;124m'\u001b[39m : y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_time\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m3600.0\u001b[39m\n\u001b[0;32m     18\u001b[0m }\n\u001b[1;32m---> 20\u001b[0m res \u001b[38;5;241m=\u001b[39m dag_search\u001b[38;5;241m.\u001b[39mexhaustive_search(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[1;32m~\\OneDrive\\PhD\\DAG_search\\DAG_search\\dag_search.py:1115\u001b[0m, in \u001b[0;36mexhaustive_search\u001b[1;34m(X, n_outps, loss_fkt, k, n_calc_nodes, n_processes, topk, verbose, opt_mode, max_orders, max_time, stop_thresh, unique_loss, expect_evals, pareto, **params)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m orders\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m order \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m-> 1115\u001b[0m     consts, losses, ops \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_build_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fkt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mopt_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocess_start_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpareto\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpareto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpect_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpect_evals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pareto:\n\u001b[0;32m   1118\u001b[0m         top_losses \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m losses\n",
      "File \u001b[1;32m~\\OneDrive\\PhD\\DAG_search\\DAG_search\\dag_search.py:866\u001b[0m, in \u001b[0;36mevaluate_build_order\u001b[1;34m(order, m, n, k, X, loss_fkt, topk, opt_mode, loss_thresh, start_time, max_time, expect_evals, pareto)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m     cgraph \u001b[38;5;241m=\u001b[39m adapt_ops(cgraph, order, ops)\n\u001b[1;32m--> 866\u001b[0m consts, loss \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_cgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fkt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_thresh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(loss)):\n\u001b[0;32m    868\u001b[0m     evaluate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\PhD\\DAG_search\\DAG_search\\dag_search.py:755\u001b[0m, in \u001b[0;36mevaluate_cgraph\u001b[1;34m(cgraph, X, loss_fkt, opt_mode, loss_thresh)\u001b[0m\n\u001b[0;32m    753\u001b[0m     consts, loss \u001b[38;5;241m=\u001b[39m get_consts_grid(cgraph, X, loss_fkt)\n\u001b[0;32m    754\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m opt_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrid_zoom\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 755\u001b[0m     consts, loss \u001b[38;5;241m=\u001b[39m \u001b[43mget_consts_grid_zoom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fkt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m opt_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrid_zoom_tan\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    757\u001b[0m     consts, loss \u001b[38;5;241m=\u001b[39m get_consts_grid_zoom(cgraph, X, loss_fkt, use_tan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\OneDrive\\PhD\\DAG_search\\DAG_search\\dag_search.py:409\u001b[0m, in \u001b[0;36mget_consts_grid_zoom\u001b[1;34m(cgraph, X, loss_fkt, interval_lower, interval_upper, n_steps, n_zooms, use_tan)\u001b[0m\n\u001b[0;32m    407\u001b[0m stepsize \u001b[38;5;241m=\u001b[39m interval_size\u001b[38;5;241m/\u001b[39m(n_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m zoom \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_zooms):\n\u001b[1;32m--> 409\u001b[0m     c, loss \u001b[38;5;241m=\u001b[39m \u001b[43mget_consts_grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fkt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterval_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minterval_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_tan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_tan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    410\u001b[0m     interval_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mstepsize\n\u001b[0;32m    411\u001b[0m     stepsize \u001b[38;5;241m=\u001b[39m interval_size\u001b[38;5;241m/\u001b[39m(n_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\OneDrive\\PhD\\DAG_search\\DAG_search\\dag_search.py:379\u001b[0m, in \u001b[0;36mget_consts_grid\u001b[1;34m(cgraph, X, loss_fkt, c_init, interval_size, n_steps, return_arg, use_tan)\u001b[0m\n\u001b[0;32m    377\u001b[0m     losses \u001b[38;5;241m=\u001b[39m loss_fkt(X, cgraph, np\u001b[38;5;241m.\u001b[39mtan(consts))\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     losses \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fkt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m best_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(losses)\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m consts[best_idx], losses[best_idx]\n",
      "File \u001b[1;32m~\\OneDrive\\PhD\\DAG_search\\DAG_search\\dag_search.py:91\u001b[0m, in \u001b[0;36mMSE_loss_fkt.__call__\u001b[1;34m(self, X, cgraph, c)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m     89\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 91\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mcgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m     losses \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean((pred\u001b[38;5;241m.\u001b[39mreshape(r, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutp\u001b[38;5;241m.\u001b[39mflatten())\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;66;03m# must not be nan or inf\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\PhD\\DAG_search\\DAG_search\\comp_graph.py:766\u001b[0m, in \u001b[0;36mCompGraph.evaluate\u001b[1;34m(self, X, c, return_grad)\u001b[0m\n\u001b[0;32m    763\u001b[0m             final_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_funcs[\u001b[38;5;241m0\u001b[39m])[:, :, np\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[0;32m    764\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    765\u001b[0m             \u001b[38;5;66;03m#final_result = np.stack([self.eval_funcs[i](X_full, c_full) for i in range(self.outp_dim)], axis = -1)\u001b[39;00m\n\u001b[1;32m--> 766\u001b[0m             final_result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([\u001b[38;5;28meval\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_funcs[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutp_dim)], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    767\u001b[0m         \u001b[38;5;66;03m#final_result = np.transpose(final_result, [1, 2, 0])\u001b[39;00m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_grad:\n",
      "File \u001b[1;32m~\\OneDrive\\PhD\\DAG_search\\DAG_search\\comp_graph.py:766\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    763\u001b[0m             final_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_funcs[\u001b[38;5;241m0\u001b[39m])[:, :, np\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[0;32m    764\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    765\u001b[0m             \u001b[38;5;66;03m#final_result = np.stack([self.eval_funcs[i](X_full, c_full) for i in range(self.outp_dim)], axis = -1)\u001b[39;00m\n\u001b[1;32m--> 766\u001b[0m             final_result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([\u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_funcs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutp_dim)], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    767\u001b[0m         \u001b[38;5;66;03m#final_result = np.transpose(final_result, [1, 2, 0])\u001b[39;00m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_grad:\n",
      "File \u001b[1;32m<string>:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_full' is not defined"
     ]
    }
   ],
   "source": [
    "# define loss function\n",
    "loss_fkt = dag_search.MSE_loss_fkt(y)\n",
    "\n",
    "# search\n",
    "params = {\n",
    "    'X' : X,\n",
    "    'n_outps' : y.shape[1],\n",
    "    'loss_fkt' : loss_fkt,\n",
    "    'k' : 1,\n",
    "    'n_calc_nodes' : 1,\n",
    "    'n_processes' : 1,\n",
    "    'topk' : 5,\n",
    "    'opt_mode' : 'grid_zoom',\n",
    "    'verbose' : 2,\n",
    "    'max_orders' : 10000, \n",
    "    'stop_thresh' : 1e-4,\n",
    "    'max_time' : 3600.0\n",
    "}\n",
    "\n",
    "res = dag_search.exhaustive_search(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0025858",
   "metadata": {},
   "source": [
    "Lets view the solutions found.\n",
    "\n",
    "The result is a dictionary containing the top-k solutions that were encountered.\n",
    "\n",
    "Each solution consists of a `graph` and its `constants`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9ff3a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = 0 # solution number\n",
    "graph = res['graphs'][idx]\n",
    "consts = res['consts'][idx]\n",
    "loss = res['losses'][idx]\n",
    "print(f'Loss: {loss}')\n",
    "\n",
    "comp_graph.plot_cgraph(graph, ax = plt.gca())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6132702d",
   "metadata": {},
   "source": [
    "The graph can be evaluated symbolically and will return a list of symbolic expressions (one for each output dimension):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a548eec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "exprs = graph.evaluate_symbolic(c = consts)\n",
    "for expr in exprs:\n",
    "    print(expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce77d21",
   "metadata": {},
   "source": [
    "Or it can be evaluated numerically for prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62690bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "pred = graph.evaluate(X, c = consts)\n",
    "\n",
    "\n",
    "# plotting\n",
    "fig, axs = plt.subplots(ncols = y.shape[1])\n",
    "for i in range(y.shape[1]):\n",
    "    axs[i].scatter(X[:, 0], y[:, i], label = 'truth')\n",
    "    axs[i].scatter(X[:, 0], pred[:, i], marker = 'x', color = 'red', label = 'predicted')\n",
    "    axs[i].legend()\n",
    "    axs[i].set_ylabel(f'$f(x)_{i}$')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0267f586",
   "metadata": {},
   "source": [
    "### Sample Search\n",
    "\n",
    "Lets go trough the same pipeline for the sampling search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a02257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function\n",
    "loss_fkt = dag_search.MSE_loss_fkt(y)\n",
    "\n",
    "params = {\n",
    "    'X' : X,\n",
    "    'n_outps' : y.shape[1],\n",
    "    'loss_fkt' : loss_fkt,\n",
    "    'k' : 1,\n",
    "    'n_calc_nodes' : 5,\n",
    "    'n_processes' : 1,\n",
    "    'topk' : 5,\n",
    "    'opt_mode' : 'grid_zoom',\n",
    "    'verbose' : 2,\n",
    "    'n_samples' : 10000,\n",
    "    'stop_thresh' : 1e-4\n",
    "    \n",
    "}\n",
    "res = dag_search.sample_search(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462729ef",
   "metadata": {},
   "source": [
    "Select a solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22756570",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0 # solution number\n",
    "graph = res['graphs'][idx]\n",
    "consts = res['consts'][idx]\n",
    "loss = res['losses'][idx]\n",
    "print(f'Loss: {loss}')\n",
    "\n",
    "comp_graph.plot_cgraph(graph, ax = plt.gca())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056a06a6",
   "metadata": {},
   "source": [
    "And evaluate it symbolically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e50934",
   "metadata": {},
   "outputs": [],
   "source": [
    "exprs = graph.evaluate_symbolic(c = consts)\n",
    "for expr in exprs:\n",
    "    print(expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9e8d18",
   "metadata": {},
   "source": [
    "Or numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08011b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "pred = graph.evaluate(X, c = consts)\n",
    "\n",
    "\n",
    "# plotting\n",
    "fig, axs = plt.subplots(ncols = y.shape[1])\n",
    "for i in range(y.shape[1]):\n",
    "    axs[i].scatter(X[:, 0], y[:, i], label = 'truth')\n",
    "    axs[i].scatter(X[:, 0], pred[:, i], marker = 'x', color = 'red', label = 'predicted')\n",
    "    axs[i].legend()\n",
    "    axs[i].set_ylabel(f'$f(x)_{i}$')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a787887c",
   "metadata": {},
   "source": [
    "## Custom Loss Function - Classification\n",
    "\n",
    "The DAG search is not restricted to Regression tasks. In fact we can define **any loss function that depends on the function- or the gradient values**.\\\n",
    "The only restriction is that the target minimum has to be 0.\n",
    "\n",
    "Lets consider the problem of finding a classification function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a93772",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "X, y = make_circles(n_samples=500, noise=0.1, factor=0.2, random_state=1)\n",
    "plt.scatter(X[:, 0], X[:, 1], c = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f702d21",
   "metadata": {},
   "source": [
    "Our goal is to find a function $f$, such that we can classify using\n",
    "\\begin{align}\n",
    "\\kappa(x_0, x_1) = \\begin{cases}\n",
    "1&\\text{, if }f(x_1, x_0) < 0\\\\\n",
    "0&\\text{, if }f(x_1, x_0) \\geq 0\\\\\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "\n",
    "We can formulate this as an optimization problem with a loss function\n",
    "\\begin{align}\n",
    "L(f) &= 1 - \\cfrac{1}{N}\\mathbb{1}[\\kappa(X_i) = y_i]\\,,\n",
    "\\end{align}\n",
    "where we simply calculate 1 minus the accuracy if we take $f$ for classification.\n",
    "\n",
    "To define our custom loss function, we should inherit from `dag_search.DAG_Loss_fkt`.\n",
    "See the example below.\n",
    "\n",
    "Note that we evaluate for multiple constants simultaneously (parameter `r`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed074d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DAG_search import comp_graph\n",
    "import warnings\n",
    "\n",
    "class Class_loss_fkt(dag_search.DAG_Loss_fkt):\n",
    "    def __init__(self, y):\n",
    "        '''\n",
    "        Loss function for finding DAG for regression task.\n",
    "\n",
    "        @Params:\n",
    "            Here you can add any parameters that Loss function depends on.\n",
    "        '''\n",
    "        \n",
    "        # in our case, the loss function depends on the true class labels\n",
    "        super().__init__()\n",
    "        self.y = y\n",
    "        \n",
    "        \n",
    "    def __call__(self, X:np.ndarray, cgraph:comp_graph.CompGraph, c:np.ndarray) -> np.ndarray:\n",
    "        '''\n",
    "        Lossfkt(X, graph, consts)\n",
    "\n",
    "        @Params:\n",
    "            X... input for DAG (N x m)\n",
    "            cgraph... computational Graph\n",
    "            c... array of constants (2D)\n",
    "\n",
    "        @Returns:\n",
    "            Loss for different constants\n",
    "        '''\n",
    "        if len(c.shape) == 2:\n",
    "            r = c.shape[0]\n",
    "            vec = True\n",
    "        else:\n",
    "            r = 1\n",
    "            c = c.reshape(1, -1)\n",
    "            vec = False\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            \n",
    "            pred = cgraph.evaluate(X, c = c)\n",
    "            # pred : shape r x N x outp_dim\n",
    "            \n",
    "            preds = (pred[:, :, 0] < 0).astype(int) # shape r x N\n",
    "            accuracy = np.mean(preds == self.y, axis = -1) # shape r\n",
    "            losses = 1 - accuracy\n",
    "            \n",
    "            # must not be nan or inf\n",
    "            invalid = ~np.isfinite(losses)\n",
    "            \n",
    "        # consider not using inf, since optimizers struggle with this\n",
    "        losses[invalid] = 1000\n",
    "        losses[losses > 1000] = 1000\n",
    "\n",
    "        if not vec:\n",
    "            return losses[0]\n",
    "        else:\n",
    "            return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bae709",
   "metadata": {},
   "source": [
    "Next we can simply start the search process with our new loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc40544",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# define loss function\n",
    "loss_fkt = Class_loss_fkt(y)\n",
    "\n",
    "# search\n",
    "params = {\n",
    "    'X' : X,\n",
    "    'n_outps' : 1,\n",
    "    'loss_fkt' : loss_fkt,\n",
    "    'k' : 1,\n",
    "    'n_calc_nodes' : 3,\n",
    "    'n_processes' : 1,\n",
    "    'topk' : 1,\n",
    "    'opt_mode' : 'grid_zoom',\n",
    "    'verbose' : 2,\n",
    "    'max_orders' : 5000, \n",
    "    'stop_thresh' : 1e-20\n",
    "}\n",
    "\n",
    "res = dag_search.exhaustive_search(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad5771d",
   "metadata": {},
   "source": [
    "And we get the following expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b719d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "graph = res['graphs'][idx]\n",
    "consts = res['consts'][idx]\n",
    "graph.evaluate_symbolic(c = consts)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8494abec",
   "metadata": {},
   "source": [
    "Which classifies as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bb16bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (graph.evaluate(X, c = consts)[:, 0] < 0).astype(int)\n",
    "expr = str(graph.evaluate_symbolic(c = consts)[0])\n",
    "plt.title(f'{expr}\\nAccuracy: {np.mean(pred == y)}')\n",
    "\n",
    "# plot decision boundary\n",
    "\n",
    "dx, dy = 0.01, 0.01\n",
    "# generate grids + labels\n",
    "x1, x2 = np.mgrid[\n",
    "    slice(np.min(X[:, -2]), np.max(X[:, -2]) + dy, dy),\n",
    "    slice(np.min(X[:, -1]), np.max(X[:, -1]) + dx, dx),\n",
    "]\n",
    "points = np.stack([x1.flatten(), x2.flatten()]).T\n",
    "labels = (graph.evaluate(points, c = consts)[:, 0] < 0).astype(int)\n",
    "labels = labels.reshape(x1.shape)\n",
    "\n",
    "# plot points + areas\n",
    "cmap = plt.get_cmap(\"bwr\")\n",
    "plt.gca().contourf(\n",
    "    x1,\n",
    "    x2,\n",
    "    labels,\n",
    "    cmap=cmap,\n",
    "    alpha=0.4,\n",
    "    vmin=0,\n",
    "    vmax=1\n",
    ")\n",
    "#plt.colorbar()\n",
    "plt.scatter(X[:, -2], X[:, -1], c=y, cmap=\"bwr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37df799c",
   "metadata": {},
   "source": [
    "## Custom Loss Function - Solving ODEs\n",
    "\n",
    "The computational DAG class can also use the [PyTorch](https://pytorch.org/) autodiff engine.\n",
    "This allows the formulation of Loss functions that depend on the gradient of the expression.\n",
    "\n",
    "Lets go trough an example by solving an **O**rdinary **D**ifferential **E**quation (ODE):\n",
    "\n",
    "For a given function $f(t, y)$, we are looking for a function $y(t)$ with $y'(t) = f(t, y)$.\n",
    "\n",
    "Let for example \n",
    "\\begin{align}\n",
    "f(t, y) = 0.25y\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c12df7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ode(t, y):\n",
    "    # t... shape N x 1\n",
    "    # y... shape r x N x d\n",
    "    # result... shape r x N x d\n",
    "    return 0.25*y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860934cb",
   "metadata": {},
   "source": [
    "We can formulate the loss function as the MSE between $f(t, y)$ and $y'$.\n",
    "\n",
    "Note how we use the `return_grad` keyword to get $y'$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384d18c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DAG_search import comp_graph\n",
    "import warnings\n",
    "\n",
    "class ODE_loss_fkt(dag_search.DAG_Loss_fkt):\n",
    "    def __init__(self, ode_func):\n",
    "        '''\n",
    "        Loss function for finding DAG for regression task.\n",
    "\n",
    "        @Params:\n",
    "            Here you can add any parameters that Loss function depends on.\n",
    "        '''\n",
    "        \n",
    "        # in our case, the loss function depends on the true class labels\n",
    "        super().__init__()\n",
    "        self.ode_func = ode_func\n",
    "        \n",
    "        \n",
    "    def __call__(self, X:np.ndarray, cgraph:comp_graph.CompGraph, c:np.ndarray) -> np.ndarray:\n",
    "        '''\n",
    "        Lossfkt(X, graph, consts)\n",
    "\n",
    "        @Params:\n",
    "            X... time series (N x 1)\n",
    "            cgraph... computational Graph\n",
    "            c... array of constants (2D)\n",
    "\n",
    "        @Returns:\n",
    "            Loss for different constants\n",
    "        '''\n",
    "        t = X\n",
    "        if len(c.shape) == 2:\n",
    "            r = c.shape[0]\n",
    "            vec = True\n",
    "        else:\n",
    "            r = 1\n",
    "            c = c.reshape(1, -1)\n",
    "            vec = False\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            y, y_ = cgraph.evaluate(t, c = c, return_grad = True)\n",
    "            # y : shape r x N x d\n",
    "            # y' : shape r x d x N x 1\n",
    "            \n",
    "            \n",
    "            term1 = self.ode_func(t, y).reshape(r, -1)\n",
    "            term2 = np.transpose(y_[:, :, :, 0], (0, 2, 1)).reshape(r, -1)\n",
    "            losses = np.mean((term1 - term2)**2, axis = -1)\n",
    "            \n",
    "            # sort out constant functions\n",
    "            tmp = np.var(y_[:, :, :, 0], axis= -1) # r x d\n",
    "            mask = np.all(tmp  <= 1e-5, axis = -1) # r \n",
    "            losses[mask] = 1000\n",
    "            \n",
    "            mask = np.any(np.abs(y.reshape(r, -1)) > 1e10, axis = -1)\n",
    "            losses[mask] = 1000\n",
    "            \n",
    "              \n",
    "            # must not be nan or inf\n",
    "            invalid = ~np.isfinite(losses)\n",
    "            \n",
    "        # consider not using inf, since optimizers struggle with this\n",
    "        losses[invalid] = 1000\n",
    "        losses[losses > 1000] = 1000\n",
    "\n",
    "        if not vec:\n",
    "            return losses[0]\n",
    "        else:\n",
    "            return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa5b30d",
   "metadata": {},
   "source": [
    "And now we have everything to start the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b68ed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# define loss function\n",
    "t = np.linspace(1, 10, 100).reshape(-1, 1)\n",
    "loss_fkt = ODE_loss_fkt(ode)\n",
    "\n",
    "# search\n",
    "params = {\n",
    "    'X' : t,\n",
    "    'n_outps' : 1,\n",
    "    'loss_fkt' : loss_fkt,\n",
    "    'k' : 1,\n",
    "    'n_calc_nodes' : 2,\n",
    "    'n_processes' : 1,\n",
    "    'topk' : 5,\n",
    "    'opt_mode' : 'grid_zoom',\n",
    "    'verbose' : 2,\n",
    "    'max_orders' : 10000, \n",
    "    'stop_thresh' : 1e-30\n",
    "}\n",
    "\n",
    "res = dag_search.exhaustive_search(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f7bd1b",
   "metadata": {},
   "source": [
    "Lets see what we got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a2af4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph, consts = res['graphs'][0], res['consts'][0]\n",
    "graph.evaluate_symbolic(c = consts)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3504f3a4",
   "metadata": {},
   "source": [
    "Indeed, if $y(t) = e^{0.25t}$, we have that\n",
    "\\begin{align}\n",
    "f(t, y) &= 0.25y\\\\\n",
    "&= 0.25e^{0.25t}\\\\\n",
    "&= y'(t)\n",
    "\\end{align}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
